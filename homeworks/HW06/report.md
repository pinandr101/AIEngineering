# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12000, 30)
- Целевая переменная: `target`, бинарная классификация: 0 и 1.
 - Распределение классов:
  - Класс 0: ~68%
  - Класс 1: ~32%
- Признаки: 24 числовых признака типа float64

## 2. Protocol

- Разбиение: train/test
 - Распределение: 80% train, 20% test
 - `random state`: 42 - фиксированный сид рандомайзера выборок
 - `stratify`: y - сохранение распределения классов таким же, как и в изначальном датасете

- Подбор: CV на train
 - Количество фолдов: 5
 - Метрика оценивания: ROC-AUC
 - Были оптимизированы следующие параметры:
  - Logistic regression: `C`
  - Decision Tree: `max_depth`, `min_samples_leaf`
  - Random Forest: `max_depth`, `max_features`
  - Gradient Boosting: `learning_rate`, `max_depth`

- Метрики:
 - `accuracy`: общая точность
 - `ROC-AUC`: основная метрика сравнений моделей
 - `f1_score`: гармоническое среднее между точностью и полнотой

## 3. Models

В ходе данной работы был использован набор разных моделей моделей с следующими параметрами:

- DummyClassifier (baseline)
 - `strategy`: most_frequent
 - `random_state`: 42

- LogisticRegression (baseline из S05)
 - Был использован pipeline, состоящий из StandardScaler, который нормировал все значения, и самой LogisticRegression
 - Был использован GridSeaarchCV для поиска наилучшего значения параметра C - обратной силы регуляризации
 - `random_state`: 42
 - `max_iter`: 1000

- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`)
 - Был использован GridSearchCV для поиска наилучших значений параметров контроля сложности `max_depth` - максимальной глубины - и `min_samples_leaf` - минимальное количество образцов в листе дерева
 - `random_state`: 42

- RandomForestClassifier
 - `n_estimators`: количество деревьев в ансамбле. Было взято оптимальное значение параметра - 100 - без перебора с помощью кросс-валидации
 - Был использован GridSearchCv для поиска наилучшего значения параметра максимальной глубины `max_depth`
 - Параметру `max_features`, отвечающему за максимальное количество признаков, которое рассматривается при поиске лучшего разделения в каждом узле дерева, была задано оптимальным "стандартным выбором" `sqrt`

- GradientBoostingClassifier
 - `n_estimators`: количество дерьвьев в ансамбле. Было взято оптимальное значение параметра - 100 - без перебора с помощью кросс-валидации
 - Был использован GridSearchCV для поиска наилучших значений параметров скорости обучения `learning_rate` и максимальной глубины `max_depth`
 - `random_state`: 42

- StackingClassifier (с CV-логикой)
 - Модели DecisionTreeClassifier, RandomForestClassifier и GradientBoostingClassifier
 - Мета-модель LogisticRegression
 - `cv` = 5: 5-фолдовая кросс-валидация
 - `random_state`: 42

## 4. Results

Model;Accuracy;F1_score;ROC-AUC
DummyClassifier;0.6767;0;0.5
LogisticRegression;0.8275;0.7080;0.8747
DecisionTree;0.8763;0.8052;0.9118
RandomForest;0.9254;0.8783;0.9673
GradientBoosting;0.9317;0.8908;0.9695
StackingClassifier;0.9300;0.8897;0.9679

- Выбор лучшей модели производился по метрике ROC-AUC. Таковой оказалась модель GradientBoosting. Заметим, что она оказалось лучшей и по всем остальным метрикам.

## 5. Analysis

- Устойчивость: при изменении занчения параметра random_state показатели метрик изменяются меньше, чем на 1% от среднего. Следовательно, модель демонстрирует высокую устойчивость.
- Ошибки: 
  
  Gradient Boosting Classifier confusion matrix:
  [[1575   49]
  [ 130  646]]

 - TN = 1575 - правильно предсказанные отрицательные случаи (класс 0)
 - FP = 49 - ложно помеченные как положительные, но на самом деле - отрицательные классы
 - FN = 130 - пропущенные положительное
 - TN = 646 - приавльно предсказанные положительные случаи

 Видно, что общая точность достаточно хороша, а также есть баланс между типами ошибок: ложных срабатываний ~2%, пропусков ~5%. Соотношение FP/FN=38% показывает, что модель чаще пропускает, чем ошибается. Это факт может быть важно знать при решении разных бизнес-задач. Ещё одно наблюдение: модель в целом лучше справляется с отрицательным классом.

- Интерпретация: пронализируем получившийся топ признаков по важности, представленный по пути: `./artifacts/figures/feature_importance.png`. Удалось подтвердить гипотезу, сделанные на этапе предварительного исследования с помощью корреляции: num18 И num19 действительно являются самыми важными признаками для данной модели. Также обнаружились неожиданные находки: например, признак num07 оказался важнее, чем ожидалось. Модель сумела обучиться на действительно важных паттернах и нашла сложные зависимости, которые не были очевидны из простого статистического анализа, оправдав необходимость применения нелинейной модели для решения поставленной задачи.

## 6. Conclusion

По результатам данной работы можно сделать несколько выводов:

Деревья и ансамбли:
-При работе с деревьями и ансамблями чрезвычайно важен контроль сложности, так как эти модели более склонны к переобучению и подбор гиперпараметров становится критически необходимой задачей.
-Ансамбли деревьев ведут себя стабильнее и показывают более хорошие результаты, чем одиночные модели в рамках поставленной задачи. Это лишь подчёркивает необходимость использования более сложных моделей в определённых случаях, чтобы замечать необычные взаимосвзязи между полями.
-Объединение разных ансамблей в один Stacking Classifier может скомпенсировать слабые стороны каждой отдельно взятой модели и повысить общую эффективность.

Честный ML-протокол:
-Разделение данных на выборки должно быть воспроизводимым. Фиксированный random_state и stratify гарантируют корректное сравнение моделей.
-Сравнение полученной модели с бейзлайном обязательно. DummyClassifier позволяет понять, насколько умная модель справляется лучше случайного угадывания в рамках поставленной задачи.