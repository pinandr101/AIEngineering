# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (15000, 8)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: разные шкалы, выбросы, высокая размерность

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (8000, 4)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: выбросы, шум

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (15000, 5)
- Признаки: числовые
- Пропуски: нет
- "Подлости" датасета: выбросы, шум, разные шкалы

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: добавили заполнение пропусков медианным значением (несмотря на то, что в предоставленных датасетах не было пропусков. Это было сделано для того, чтобы в дальнейшем можно было делать препроцессинг любых датасетов, подаваемых на вход, даже с пропусками), а также стандартизировали все значения
- Поиск гиперпараметров:
  - KMeans: k - количество кластеров. Перебирали целые числа из промежутка [2, 20]
  - AgglomerativeClustering: k - количество кластеров - перебирали целые числа из промежутка [2, 20], linkage - метод связи - выбирали между двумя: ward и complete
  - DBScan: параметры eps - радиус окрестности - и min_samples - количество точек, которое должно находиться в радиусе - перебирали парами, где eps мог принимать значения 0.3, 0.5, 0.7, 1.0, 1.5, 2.0, a min_samples либо 5, либо 10. 
  - Выбор лучшей конфигурации осуществлялся на основе метрики silhouette
- Метрики: silhouette / Davies-Bouldin / Calinski-Harabasz. Для DBScan метрики считались на non-noise точках.
- Визуализация: PCA(2D)

## 3. Models

Перечислите, какие модели сравнивали **на каждом датасете**, и какие параметры подбирали.

На каждом датасете сравнивали три модели:
- KMeans (поиск `k`, фиксировали `random_state`, `n_init`)
- AgglomerativeClustering (`k`, `linkage`)
- DBSCAN (`eps`, `min_samples`)

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры: DBScan (eps: 2.0, min_samples: 5)
- Метрики (silhouette / DB / CH): 0.5216/0.6853/11786.9546
- Если был DBSCAN: Доля шума = 0% - идеально чистый датасет
- Самый чистый из всех. Здесь практически не было шумов и кластеры имели формы более менее приближённые к сферической. Благодаря этому все модели справились с ним достаточно хорошо. Удалось разделить две большие группы объектов на два соответствующих кластера, а значит, модель отработала приемлемо.

### 4.2 Dataset B

- Лучший метод и параметры: KMeans (k=2)
- Метрики (silhouette / DB / CH): 0.3069/1.3235/3573.3977
- Имел большое скопление точек посередине и множество выбросов вокруг, что не позволяло явно разделить его на два кластера, из-за чего многие алгоритмы путались. Здесь лучше всего справился самый обычный kmeans, так как он просто разделил объекты пополам на два практически равных кластера, не пытаясь "сильно думать". Это немного нестандартный датасет для задачи кластеризации, так как кластеризация подразумевает собой разделение данных на **несколько** кластеров. Тут же, если судить по графику, как будто лучшим варинатом было бы просто сделать одну единую группу посередине, а всё остальное считать шумом. Поэтому будем считать решение KMeans приемлемым: он **разделил** данные на кластеры, как ему и полагалось сделать.

### 4.3 Dataset C

- Лучший метод и параметры: KMeans (k=3)
- Метрики (silhouette / DB / CH): 0.3155/1.1577/6957.1626
- Был достаточно сложным для кластеризации, так как имел неочевидные формы кластеров, разную плотность и небольшое количество шума. 

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans чаще всего "ломается" на датасетах, которые имеют выбросы, большую дисперсию в значениях признаков, а также разную плотность и нестандартную(несферическую) форму кластеров. Он плохо обрабатывает такие случаи из-за того, что обрабатывает данные сверху вниз, разделяя общее множество точек на всё большее и большее количество кластеров. Такой подход не способен обнаруживать сложные формы кластеров, лучше всего он работает для определения сферических кластеров равных размеров.
- DBScan работает умеренно хорошо на болшинстве датасетов из-за того, что умеет работать с шумом и не требует заранее заданного количества кластеров, определяя его сам в результате работы программы, что помогает больше адаптироваться под данные и найти кластеры произвольной формы.
- Наиболее критично на результаты влияет масштабирование. Это лишь подтверждает необходимость в явном препроцессинге каждого датасета перед обучением моделей

### 5.2 Устойчивость (обязательно для одного датасета)

- Какую проверку устойчивости делали: 5 запусков KMeans с разным значение random_state для датасета 1
- На всех запусках модели не изменялся финальный выбор конфигурации модели: k оставался равен двум - именно при нём наблюдался максимум значения метрики silhouette, по которой и проводился отбор. Взглянув на графики, построенные в ходе тестирования устойчивости, можно лишь сделать одно интересное наблюдение: при изменении random_state появлялись локальные максимумы значения метрики, зависящей от k. Так, например, при прогоне с сидом равным 42 наблюдается отчётливый пик при k=8, который отсутсвует при других значениях random_state.
- Вывод: модель устойчива, так как при изменении сида глобальный максимум не изменяется и результат остаётся один и тот же.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - Основное интерпретирование кластеров происходило с помощью визуализации через PCA
Выводы по интерпретации в целом:
- Кластеры редко соответсвуют идеальным сферическим формам, чаще всего это перекрывающие друг друга распределения с разной плотностью и множеством выбросов
- Интерпретируемость сильно зависит от предобработки. Без масштабирования кластеризация не даст никакой полезной информации для формирования выводов
- Разные метрики отвечают за разные цели. Всегда нужно основывать выбор лучшей модели, опираясь на исходные данные: какая метрика именно для них является наиболее важной.

## 6. Conclusion

1. Предобработка - **ОЧЕНЬ** важный этап. Без масштабирования, обработки пропусков и кодирования категориальных признаков не выйдет добиться приемлемого результата даже с самыми передовыми моделями
2. Честный подсчёт метрик - важный пункт сравнения моделей. Для таких моделей, как DBScan, нужно обязательно считать метрики без учёта шумовых точек, иначе сравнение будет некорректным.
3. Важность визуализации. Нередко может выйти так, что алгоритм выигрывает по одной метрике, но ужасно сильно отстаёт по другой. Чтобы видеть всю картину целиком важно строить для каждой модели визуальное представление. В данной работе для этого использовался PCA
4. Важность подбора гиперпараметров. Невозможно дать конкретное значение модели и надеяться, что оно покажет хорошие результаты. Необходимо тщательно проанализировать предоставленный датасет и на основе данных из него уже выбрать интервалы подбора каждого параметра, так как **универсального значения не существует** - каждый датасет по-своему уникален в работе с ним.
5. Все проводимые эксперименты должны быть воспроизводимы. Сравнение моделей будет корректным только тогда, когда они все устойчивы к частичному изменению входных данных с помощью сида. Так как у каждой модели есть худший случай и лучший. Нельзя сравнивать эффективность модели, которой не повезло и попал на вход худший её случай, с той, которой попался наилучшие входные данные. Необходимо сделать несколько прогонов и протестировать модель на устойчивость с помощью разных сидов.